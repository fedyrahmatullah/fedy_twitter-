{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library python yang diperlukan\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Token Akses dari Twitter API\n",
    "access_token='CENSORED'\n",
    "access_token_secret='CENSORED'\n",
    "consumer_key='CENSORED'\n",
    "consumer_key_secret='CENSORED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses Scrapping Selesai Dengan Jumlah Data 1000\n"
     ]
    }
   ],
   "source": [
    "def scraptweets(search_words, date_since, date_until):\n",
    "\n",
    "    db_tweets = pd.DataFrame(columns=['tweetcreatedts', 'username', 'text', 'retweet_count', 'like'])#Komponen tweet yang diambil\n",
    "\n",
    "    tweets = tweepy.Cursor(\n",
    "                    api.search, q=search_words, lang=\"id\", #mencari tweet berbahasa Indonesia\n",
    "                    since=date_since, until=date_until,  tweet_mode='extended').items(1000) #crawling tweet fulltext max1000\n",
    "\n",
    "    tweet_list = [tweet for tweet in tweets]\n",
    "\n",
    "    for tweet in tweet_list:\n",
    "        username = tweet.user.screen_name\n",
    "        tweetcreatedts = tweet.created_at\n",
    "        retweet_count = tweet.retweet_count\n",
    "        like = tweet.favorite_count\n",
    "\n",
    "        try:\n",
    "            text = tweet.retweeted_status.full_text\n",
    "        except AttributeError:\n",
    "            text = tweet.full_text\n",
    "\n",
    "        ith_tweet = [tweetcreatedts, username, text, retweet_count, like]\n",
    "\n",
    "        db_tweets.loc[len(db_tweets)] = ith_tweet\n",
    "    \n",
    "    print('Proses Scrapping Selesai Dengan Jumlah Data', len(db_tweets))\n",
    "    filename = 'Crawling_Covid_beta.csv'\n",
    "    db_tweets.to_csv(filename, index=False)\n",
    "\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "last_week = datetime.today() - timedelta(7)\n",
    "last_week = last_week.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "search_words = \"covid-19\" #Kata kunci yang digunakan\n",
    "date_since = last_week\n",
    "date_until = today\n",
    "\n",
    "scraptweets(search_words, date_since, date_until)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
